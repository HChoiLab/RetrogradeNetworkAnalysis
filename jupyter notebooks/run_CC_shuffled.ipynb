{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from func_unsupervised_CC_retro import fit_retro\n",
    "from func_unsupervised_CC_antero import fit_antero\n",
    "from IterativeMethod import iterativeCC\n",
    "\n",
    "\"\"\"\n",
    "Published on Sat Mar 2 17:23:54 2024\n",
    "\n",
    "@author: Eric Li, Hannah Choi\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "This code generates shuffled versions of the CC connectivity data and \n",
    "computes the global hierarchy scores of the shuffled data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b98e797",
   "metadata": {},
   "source": [
    "# Set input and output directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f6205",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = r'./Input/'                     # Directory with the file \"AnteroRetro_CC_TC_CT_clusters.xlsx\"\n",
    "input_dir2 = r'./Output/'                   # Directory with the file \"ghc_CC.xls\"\n",
    "output_dir = r'./Output/shuffled/'          # Directory to save the ouputs from the shuffled experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a357ce",
   "metadata": {},
   "source": [
    "# Read the excel file with source-target-creline pairs and their cluster numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df59d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls=pd.ExcelFile(input_dir+\"AnteroRetro_CC_TC_CT_clusters.xlsx\")\n",
    "df=pd.read_excel(xls,'anteroCCTC_retroCCCT')\n",
    "\n",
    "df_antero=df[(df.Antero_Retro == \"A\")] \n",
    "df_antero=df_antero[(df_antero.hemi == \"ipsi\")&(df_antero.creline != \"C57BL/6J / Emx1\")&(df_antero.target != \"VISC\")&(df_antero.source != \"SSp-un\")&(df_antero.target != \"SSp-un\")&(df_antero.source != \"VISC\")] # Consider ipsilateral, Cre connectivity data only\n",
    "df_antero = df_antero[(df_antero[\"Target Major Division\"] == \"isocortex\")&(df_antero[\"Source Major Division\"] == \"isocortex\")] # Consider C-C connections only\n",
    "\n",
    "dfV1 = df_antero[['Antero_Retro','source','target','creline','AnteroCluster']]\n",
    "dfV1 = dfV1.reset_index(drop=True)\n",
    "dfV1['AnteroCluster'] = dfV1['AnteroCluster'].apply(np.int64)\n",
    "\n",
    "source_areas1 = dfV1[\"source\"].unique()\n",
    "target_areas1 = dfV1[\"target\"].unique()\n",
    "\n",
    "df_retro=df[(df.Antero_Retro == \"R\")] \n",
    "df_retro = df_retro[(df_retro[\"Target Major Division\"] == \"isocortex\")&(df_retro[\"Source Major Division\"] == \"isocortex\")]  # Consider C-C connections only\n",
    "\n",
    "dfV2 = df_retro[['Antero_Retro','source','target','creline','RetroCluster']]\n",
    "dfV2 = dfV2.reset_index(drop=True)\n",
    "dfV2['RetroCluster'] = dfV2['RetroCluster'].apply(np.int64)\n",
    "\n",
    "source_areas2 = dfV2[\"source\"].unique()\n",
    "target_areas2 = dfV2[\"target\"].unique()  \n",
    "\n",
    "dfV_antero = dfV1[[\"source\",\"target\",\"creline\",\"AnteroCluster\", \"Antero_Retro\"]].copy()\n",
    "dfV_retro = dfV2[[\"source\",\"target\",\"creline\",\"RetroCluster\", \"Antero_Retro\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8222213",
   "metadata": {},
   "source": [
    "# Find global hierarchy scores of shuffled CC connectivity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8872af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10 # or 5, for fast process\n",
    "n_shuffle = 100\n",
    "by_creline = 1   # 1 if shuffle within each Cre-line; 0 if shuffle across Cre-lines \n",
    "line_list_antero = dfV_antero[\"creline\"].unique()\n",
    "line_list_retro = dfV_retro[\"creline\"].unique()\n",
    "\n",
    "hr_init_shuffled = np.zeros(n_shuffle)\n",
    "hr_iter_shuffled = np.zeros(n_shuffle)\n",
    "hrc_iter_shuffled = np.zeros(n_shuffle)\n",
    "hrc_init_shuffled = np.zeros(n_shuffle)\n",
    "\n",
    "for i_shuffle in range(0,n_shuffle):\n",
    "    dfV_shuffled_antero = dfV_antero\n",
    "    dfV_shuffled_retro = dfV_retro\n",
    "    \n",
    "    if by_creline == 0:\n",
    "        source_list_antero = dfV_shuffled_antero.source\n",
    "        target_list_antero = dfV_shuffled_antero.target\n",
    "        source_shuffled_antero = source_list_antero.sample(frac=1).reset_index(drop=True)\n",
    "        target_shuffled_antero = target_list_antero.sample(frac=1).reset_index(drop=True)\n",
    "        source_shuffled_antero.index = source_list_antero.index\n",
    "        target_shuffled_antero.index = target_list_antero.index \n",
    "        dfV_shuffled_antero.loc[source_list_antero.index, \"source\"]=np.array(source_shuffled_antero)\n",
    "        dfV_shuffled_antero.loc[target_list_antero.index, \"target\"]=np.array(target_shuffled_antero)\n",
    "        \n",
    "        source_list_retro = dfV_shuffled_retro.source\n",
    "        target_list_retro = dfV_shuffled_retro.target\n",
    "        source_shuffled_retro = source_list_retro.sample(frac=1).reset_index(drop=True)\n",
    "        target_shuffled_retro = target_list_retro.sample(frac=1).reset_index(drop=True)\n",
    "        source_shuffled_retro.index = source_list_retro.index\n",
    "        target_shuffled_retro.index = target_list_retro.index \n",
    "        dfV_shuffled_retro.loc[source_list_retro.index, \"source\"]=np.array(source_shuffled_retro)\n",
    "        dfV_shuffled_retro.loc[target_list_retro.index, \"target\"]=np.array(target_shuffled_retro)\n",
    "        \n",
    "    elif by_creline == 1:\n",
    "        for i in range(0,len(line_list_antero)):\n",
    "            source_list_antero = dfV_shuffled_antero[(dfV_shuffled_antero.creline == str(line_list_antero[i]))].source\n",
    "            target_list_antero = dfV_shuffled_antero[(dfV_shuffled_antero.creline == str(line_list_antero[i]))].target\n",
    "            source_shuffled_antero = source_list_antero.sample(frac=1).reset_index(drop=True)\n",
    "            target_shuffled_antero = target_list_antero.sample(frac=1).reset_index(drop=True)\n",
    "            source_shuffled_antero.index = source_list_antero.index\n",
    "            target_shuffled_antero.index = target_list_antero.index        \n",
    "            dfV_shuffled_antero.loc[source_list_antero.index, \"source\"]=np.array(source_shuffled_antero)\n",
    "            dfV_shuffled_antero.loc[target_list_antero.index, \"target\"]=np.array(target_shuffled_antero)\n",
    "            \n",
    "        for i in range(0,len(line_list_retro)):\n",
    "            source_list_retro = dfV_shuffled_retro[(dfV_shuffled_retro.creline == str(line_list_retro[i]))].source\n",
    "            target_list_retro = dfV_shuffled_retro[(dfV_shuffled_retro.creline == str(line_list_retro[i]))].target\n",
    "            source_shuffled_retro = source_list_retro.sample(frac=1).reset_index(drop=True)\n",
    "            target_shuffled_retro = target_list_retro.sample(frac=1).reset_index(drop=True)\n",
    "            source_shuffled_retro.index = source_list_retro.index\n",
    "            target_shuffled_retro.index = target_list_retro.index        \n",
    "            dfV_shuffled_retro.loc[source_list_retro.index, \"source\"]=np.array(source_shuffled_retro)\n",
    "            dfV_shuffled_retro.loc[target_list_retro.index, \"target\"]=np.array(target_shuffled_retro)\n",
    "\n",
    "    frames = [dfV_shuffled_antero, dfV_shuffled_retro]\n",
    "    dfV_shuffled = pd.concat(frames)\n",
    "    dfV_shuffled['AnteroCluster'] = dfV_shuffled['AnteroCluster'].astype('Int64')\n",
    "    dfV_shuffled['RetroCluster'] = dfV_shuffled['RetroCluster'].astype('Int64')\n",
    "\n",
    "    source_areas = dfV_shuffled[\"source\"].unique()\n",
    "    target_areas = dfV_shuffled[\"target\"].unique()\n",
    "    \n",
    "    source_areas1 = set(source_areas)\n",
    "    target_areas1 = set(target_areas)\n",
    "\n",
    "    areas = np.array(list(source_areas1.intersection(target_areas1)))\n",
    "    n_areas=len(areas)\n",
    "    \n",
    "    num_antero_clu = len(dfV_shuffled[\"AnteroCluster\"].unique())-1\n",
    "    num_retro_clu = len(dfV_shuffled[\"RetroCluster\"].unique())-1\n",
    "    dfV_shuffled = dfV_shuffled.reset_index(drop=True)\n",
    "        \n",
    "    hierarchy_vals_antero = fit_antero(dfV_shuffled_antero)\n",
    "        \n",
    "    jmax_raw_antero, jmax_antero = np.argmax(hierarchy_vals_antero, axis=0)\n",
    "    jmax_raw_val_antero = hierarchy_vals_antero[jmax_raw_antero][0]\n",
    "    jmax_val_antero = hierarchy_vals_antero[jmax_antero][1]\n",
    "    logging.debug(\"RESULTS\")\n",
    "    n_a = num_antero_clu\n",
    "    logging.debug(\"(jmax_raw_antero, val) = ({:0{n}b}, {:.3f})\".format(jmax_raw_antero, jmax_raw_val_antero, n=n_a))\n",
    "    logging.debug(\"(jmax_antero,     val) = ({:0{n}b}, {:.3f})\".format(jmax_antero, jmax_val_antero, n=n_a))\n",
    "\n",
    "    results_antero = dict(jmax_antero=bin(2**n_a+jmax_antero),\n",
    "               jmax_val_antero=jmax_val_antero,\n",
    "               jmax_raw_antero=bin(2**n_a+jmax_raw_antero),\n",
    "               jmax_raw_val_antero=jmax_raw_val_antero)\n",
    "    \n",
    "    hierarchy_vals_retro = fit_retro(dfV_shuffled_retro)\n",
    "        \n",
    "    jmax_raw_retro, jmax_retro = np.argmax(hierarchy_vals_retro, axis=0)\n",
    "    jmax_raw_val_retro = hierarchy_vals_retro[jmax_raw_retro][0]\n",
    "    jmax_val_retro = hierarchy_vals_retro[jmax_retro][1]\n",
    "    logging.debug(\"RESULTS\")\n",
    "    n_r = num_retro_clu\n",
    "    logging.debug(\"(jmax_raw_retro, val) = ({:0{n}b}, {:.3f})\".format(jmax_raw_retro, jmax_raw_val_retro, n=n_r))\n",
    "    logging.debug(\"(jmax_retro,     val) = ({:0{n}b}, {:.3f})\".format(jmax_retro, jmax_val_retro, n=n_r))\n",
    "\n",
    "    results_retro = dict(jmax_retro=bin(2**n_r+jmax_retro),\n",
    "               jmax_val_retro=jmax_val_retro,\n",
    "               jmax_raw_retro=bin(2**n_r+jmax_raw_retro),\n",
    "               jmax_raw_val_retro=jmax_raw_val_retro)\n",
    "    \n",
    "    print('i_shuffle='+str(i_shuffle))\n",
    "    \n",
    "    ###########################################################################    \n",
    "    \"\"\"Define functions needed\"\"\"\n",
    "    \n",
    "    c0r=2**(num_retro_clu)\n",
    "    c0a=2**(num_antero_clu)\n",
    "    \n",
    "    def ff_or_fb_retro (cls):\n",
    "        \"\"\"Direction of each retrograde CC cluster with Cre-confidence\"\"\"\n",
    "        b=(bin(c0r+jmax_retro)[-(cls)])\n",
    "        return (2*int(b)-1)\n",
    "    \n",
    "    def ff_or_fb_retro_nc (cls):\n",
    "        \"\"\"Direction of each retrograde CC cluster without Cre-confidence\"\"\"\n",
    "        b=(bin(c0r+jmax_raw_retro)[-(cls)])\n",
    "        return (2*int(b)-1)\n",
    "    \n",
    "    def ff_or_fb_antero(cls):\n",
    "        \"\"\"Direction of each anterograde CC cluster with Cre-confidence\"\"\"\n",
    "        b=(bin(c0a+jmax_antero)[-(cls)])\n",
    "        return (2*int(b)-1)\n",
    "\n",
    "    def ff_or_fb_antero_nc(cls):\n",
    "        \"\"\"Direction of each anterograde CC cluster without Cre-confidence\"\"\"\n",
    "        b=(bin(c0a+jmax_raw_antero)[-(cls)])\n",
    "        return (2*int(b)-1)\n",
    "    \n",
    "    def cre_confidence1(df):\n",
    "        \"\"\"Returns confidence of cre lines\"\"\"\n",
    "        func = lambda x: 1 - np.abs(x.mean())\n",
    "        return df.groupby('creline')['ffb_c'].transform(func)\n",
    "    \n",
    "    def hrf (area):\n",
    "        '''Hierarchy score of each area without Cre-confidence'''\n",
    "        return ((-np.mean(dfV_shuffled[dfV_shuffled.source == area].ffb_nc)\n",
    "                 +np.mean(dfV_shuffled[dfV_shuffled.target == area].ffb_nc))/2)\n",
    "    \n",
    "    def hrcf (area):\n",
    "        '''Hierarchy score of each area with Cre-confidence'''\n",
    "        return ((-np.mean(dfV_shuffled[dfV_shuffled.source == area].ffb_c*dfV_shuffled[dfV_shuffled.source == area].conf)\n",
    "                 +np.mean(dfV_shuffled[dfV_shuffled.target == area].ffb_c*dfV_shuffled[dfV_shuffled.target == area].conf))/2)\n",
    "    ###########################################################################\n",
    "    \n",
    "    ###########################################################################\n",
    "    \"\"\"Produce expanded data frame with  FF/FB, Cre-confidence, hierarchy values as source & target \n",
    "    for each pair of CC connections\"\"\"\n",
    "    \n",
    "    dfV_shuffled.loc[(dfV_shuffled.Antero_Retro == \"R\"),\"ffb_c\"]=dfV_shuffled[(dfV_shuffled.Antero_Retro == \"R\")].RetroCluster.apply(ff_or_fb_retro)\n",
    "    dfV_shuffled.loc[(dfV_shuffled.Antero_Retro == \"R\"),\"ffb_nc\"]=dfV_shuffled[(dfV_shuffled.Antero_Retro == \"R\")].RetroCluster.apply(ff_or_fb_retro_nc)\n",
    "    dfV_shuffled.loc[(dfV_shuffled.Antero_Retro == \"A\"),\"ffb_c\"]=dfV_shuffled[(dfV_shuffled.Antero_Retro == \"A\")].AnteroCluster.apply(ff_or_fb_antero)\n",
    "    dfV_shuffled.loc[(dfV_shuffled.Antero_Retro == \"A\"),\"ffb_nc\"]=dfV_shuffled[(dfV_shuffled.Antero_Retro == \"A\")].AnteroCluster.apply(ff_or_fb_antero_nc)\n",
    "    dfV_shuffled.loc[:, \"conf\"] = cre_confidence1(dfV_shuffled)\n",
    "    dfV_shuffled.loc[:,\"hrc_s\"]=dfV_shuffled[\"source\"].apply(hrcf)\n",
    "    dfV_shuffled.loc[:,\"hrc_t\"]=dfV_shuffled[\"target\"].apply(hrcf)\n",
    "    dfV_shuffled.loc[:,\"hr_s\"]=dfV_shuffled[\"source\"].apply(hrf)\n",
    "    dfV_shuffled.loc[:,\"hr_t\"]=dfV_shuffled[\"target\"].apply(hrf)\n",
    "    \n",
    "    dfV_shuffled.to_excel(output_dir+'inputexpanded_CC_shuffled'+str(i_shuffle)+'.xlsx')\n",
    "    ###########################################################################\n",
    "    \n",
    "    hrs=list(range(0,n_areas))\n",
    "    hrt=list(range(0,n_areas))\n",
    "    hr=list(range(0,n_areas))\n",
    "    hrc=list(range(0,n_areas))\n",
    "    for i in range(0,n_areas):\n",
    "        hrs[i]=-np.mean(dfV_shuffled[dfV_shuffled.source == areas[i]].ffb_nc)\n",
    "        hrt[i]=np.mean(dfV_shuffled[dfV_shuffled.target == areas[i]].ffb_nc)\n",
    "        hr[i]=(hrs[i]+hrt[i])/2\n",
    "        hrc[i]=0.5*(-np.mean(dfV_shuffled[dfV_shuffled.source == areas[i]].ffb_c*dfV_shuffled[dfV_shuffled.source == areas[i]].conf)\n",
    "        +np.mean(dfV_shuffled[dfV_shuffled.target == areas[i]].ffb_c*dfV_shuffled[dfV_shuffled.target == areas[i]].conf))\n",
    "     \n",
    "    data=[areas,hrc,hr]\n",
    "    data=np.transpose(data)\n",
    "    columns = ['areas','hrc','hr']\n",
    "    dfi_shuffled = pd.DataFrame(data,columns=columns) \n",
    "    \n",
    "    hr_iter, hrc_iter = iterativeCC(dfi_shuffled,dfV_shuffled,n_iter)\n",
    "    \n",
    "    hrc_iter = hrc_iter[['areas',0,n_iter]]\n",
    "    hr_iter = hr_iter[['areas',0,n_iter]]  \n",
    "    \n",
    "    ###########################################################################\n",
    "    '''Save hierarchy scores of cortical areas in the shuffled data'''\n",
    "    hr_iter.to_excel(output_dir+'CCshuffled_noconf_iter'+str(i_shuffle)+'.xlsx')\n",
    "    hrc_iter.to_excel(output_dir+'CCshuffled_conf_iter'+str(i_shuffle)+'.xlsx')\n",
    "    ###########################################################################\n",
    "    \n",
    "    dfV_temp = dfV_shuffled[['source','target','ffb_c','ffb_nc','conf']]\n",
    "    dfi_temp = hr_iter[['areas',0,n_iter]]\n",
    "    dfi_temp = dfi_temp.rename(columns={0: \"h0\", n_iter:\"h_iter\"})\n",
    "    dfi_temp_conf = hrc_iter[['areas',0,n_iter]]\n",
    "    dfi_temp_conf = dfi_temp_conf.rename(columns={0: \"h0\", n_iter:\"h_iter\"})\n",
    "\n",
    "    dfi_t = dfi_temp[['areas','h0','h_iter']]\n",
    "    dfV_temp = dfV_temp.join(dfi_t.set_index('areas'), on ='source')\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h_iter\": \"hs_iter\"})\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h0\": \"hs0\"})\n",
    "    dfV_temp = dfV_temp.join(dfi_t.set_index('areas'), on ='target')\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h_iter\": \"ht_iter\"})\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h0\": \"ht0\"})\n",
    "    dfV_temp = dfV_temp.dropna()\n",
    "    \n",
    "    ###########################################################################\n",
    "    '''global hierarchy score of the shuffled data before & after iteration, without Cre-confidence'''\n",
    "    hr_init_shuffled[i_shuffle] = np.mean(dfV_temp.ffb_nc*(dfV_temp.ht0 - dfV_temp.hs0))\n",
    "    hr_iter_shuffled[i_shuffle] = np.mean(dfV_temp.ffb_nc*(dfV_temp.ht_iter - dfV_temp.hs_iter))\n",
    "    \n",
    "    dfV_temp = dfV_shuffled[['source','target','ffb_c','ffb_nc','conf']]\n",
    "    dfi_t = dfi_temp_conf[['areas','h0','h_iter']]\n",
    "    dfV_temp = dfV_temp.join(dfi_t.set_index('areas'), on ='source')\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h_iter\": \"hs_iter\"})\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h0\": \"hs0\"})\n",
    "    dfV_temp = dfV_temp.join(dfi_t.set_index('areas'), on ='target')\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h_iter\": \"ht_iter\"})\n",
    "    dfV_temp =dfV_temp.rename(columns={\"h0\": \"ht0\"})\n",
    "    dfV_temp = dfV_temp.dropna() \n",
    "    \n",
    "     ###########################################################################\n",
    "    '''global hierarchy score of the shuffled data before & after iteration, with Cre-confidence'''   \n",
    "    hrc_init_shuffled[i_shuffle] = np.mean(dfV_temp.ffb_c*(dfV_temp.ht0 - dfV_temp.hs0))\n",
    "    hrc_iter_shuffled[i_shuffle] = np.mean(dfV_temp.ffb_c*(dfV_temp.ht_iter - dfV_temp.hs_iter))\n",
    "    ###########################################################################    \n",
    "    \n",
    "pd.DataFrame(hrc_init_shuffled).to_excel(output_dir +'CC_hg_init_shuffled.xlsx')\n",
    "pd.DataFrame(hrc_iter_shuffled).to_excel(output_dir +'CC_hg_iter_shuffled.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849aceb",
   "metadata": {},
   "source": [
    "# Plot global hierarchy scores of 100 shuffled data with the global hierarchy score of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Global hierarchy scores of the original cortico-cortical connectivity\"\"\"\n",
    "df_hg_CC = pd.read_excel(input_dir2+'ghs_CC.xlsx')\n",
    "\n",
    "hg_CC_conf_init = df_hg_CC[\"hg_CC_conf_init\"][0]\n",
    "hg_CC_conf_iter = df_hg_CC[\"hg_CC_conf_iter\"][0]\n",
    "\n",
    "hmc_init = (hg_CC_conf_init-np.mean(hrc_init_shuffled))/np.std(hrc_init_shuffled) # Z-score before iteration\n",
    "hmc_iter = (hg_CC_conf_iter-np.mean(hrc_iter_shuffled))/np.std(hrc_iter_shuffled) # Z-score after iteration\n",
    "\n",
    "\"\"\" Figure showing global hierarchy scores of shuffled data & original CC data before & after iteration \"\"\"\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(hrc_init_shuffled, bins=10, label='before iterate')\n",
    "ax.axvline(x=hg_CC_conf_init,linestyle='--')\n",
    "ax.hist(hrc_iter_shuffled, bins=10, label='after iterate',color='red')\n",
    "ax.axvline(x=hg_CC_conf_iter,linestyle='--',color='red')\n",
    "ax.set_xlabel('global hierarchy score',fontsize=16)\n",
    "ax.set_ylabel('counts',fontsize=16)\n",
    "ax.set_title('hmc(init)='+str(hmc_init)+'; hmc(iter)='+str(hmc_iter))\n",
    "ax.legend(loc='upper right')\n",
    "#fig.savefig(output_dir+\"shuffled_globalhierarchy_conf_CC.pdf\", bbox_inches='tight')\n",
    "\n",
    "\"\"\" Figure showing global hierarchy scores of shuffled data & original CC data before iteration \"\"\"\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(hrc_init_shuffled, bins=10, label='before iterate')\n",
    "ax.axvline(x=hg_CC_conf_init,linestyle='--')\n",
    "ax.set_xlabel('global hierarchy score',fontsize=16)\n",
    "ax.set_ylabel('counts',fontsize=16)\n",
    "ax.set_title('hm(init)='+str(hmc_init))\n",
    "ax.legend(loc='upper right')\n",
    "#fig.savefig(output_dir+\"shuffled_globalhierarchy_CC_init.pdf\", bbox_inches='tight')\n",
    "\n",
    "\"\"\" Figure showing global hierarchy scores of shuffled data & original CC data after iteration \"\"\"\n",
    "fig,ax=plt.subplots()\n",
    "ax.hist(hrc_iter_shuffled, bins=10, label='after iterate',color='red')\n",
    "ax.axvline(x=hg_CC_conf_iter,linestyle='--',color='red')\n",
    "ax.set_xlabel('global hierarchy score',fontsize=16)\n",
    "ax.set_ylabel('counts',fontsize=16)\n",
    "ax.set_title('hm(iter)='+str(hmc_iter))\n",
    "ax.legend(loc='upper right')\n",
    "#fig.savefig(output_dir+\"shuffled_globalhierarchy_CC_iter.pdf\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
